{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv  # to make sure environment variables are loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)  # sets environment variables, the .env file has priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()  # creating an instance (object) of the OpenAI class calle openai\n",
    "# OpenAI is the client (wrapper) library that allows us to interact with the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "# conversations with LLM is always lists with dictionaries! Like so:\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\",\n",
    "    \"content\": \"What is 2+2?\"}\n",
    "    ]\n",
    "# I prefer to format it like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "# This is the fixed structure of calling the OpenAI API\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)  # simple test to check if it works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]  # remember that this is the format for conversations with LLMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If 7 people can complete a task in 15 days working 8 hours a day, how many people are required to complete the same task in 10 days working 10 hours a day?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content  # remember that this is also the format to get the response from the LLM\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]  # having the LLM answer it's own question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the problem step by step:\n",
      "\n",
      "### Given:\n",
      "- 7 people\n",
      "- 15 days\n",
      "- 8 hours per day\n",
      "- Task is completed\n",
      "\n",
      "### To Find:\n",
      "Number of people required to complete the same task in:\n",
      "- 10 days\n",
      "- 10 hours per day\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Calculate the total work done in terms of \"person-hours\".\n",
      "\n",
      "Work done = Number of people × Number of days × Hours per day\n",
      "\n",
      "For the original scenario:\n",
      "\\[\n",
      "\\text{Total work} = 7 \\times 15 \\times 8 = 840 \\text{ person-hours}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Define the number of people required as \\(x\\).\n",
      "\n",
      "We want to complete the same amount of work (840 person-hours) in 10 days, 10 hours per day:\n",
      "\\[\n",
      "x \\times 10 \\times 10 = 840\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### Step 3: Solve for \\(x\\):\n",
      "\\[\n",
      "100x = 840 \\implies x = \\frac{840}{100} = 8.4\n",
      "\\]\n",
      "\n",
      "Since the number of people must be whole (usually), **9 people** are required.\n",
      "\n",
      "---\n",
      "\n",
      "### Final answer:\n",
      "\\[\n",
      "\\boxed{9 \\text{ people}}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's analyze the problem step by step:\n",
       "\n",
       "### Given:\n",
       "- 7 people\n",
       "- 15 days\n",
       "- 8 hours per day\n",
       "- Task is completed\n",
       "\n",
       "### To Find:\n",
       "Number of people required to complete the same task in:\n",
       "- 10 days\n",
       "- 10 hours per day\n",
       "\n",
       "---\n",
       "\n",
       "### Step 1: Calculate the total work done in terms of \"person-hours\".\n",
       "\n",
       "Work done = Number of people × Number of days × Hours per day\n",
       "\n",
       "For the original scenario:\n",
       "\\[\n",
       "\\text{Total work} = 7 \\times 15 \\times 8 = 840 \\text{ person-hours}\n",
       "\\]\n",
       "\n",
       "---\n",
       "\n",
       "### Step 2: Define the number of people required as \\(x\\).\n",
       "\n",
       "We want to complete the same amount of work (840 person-hours) in 10 days, 10 hours per day:\n",
       "\\[\n",
       "x \\times 10 \\times 10 = 840\n",
       "\\]\n",
       "\n",
       "---\n",
       "\n",
       "### Step 3: Solve for \\(x\\):\n",
       "\\[\n",
       "100x = 840 \\implies x = \\frac{840}{100} = 8.4\n",
       "\\]\n",
       "\n",
       "Since the number of people must be whole (usually), **9 people** are required.\n",
       "\n",
       "---\n",
       "\n",
       "### Final answer:\n",
       "\\[\n",
       "\\boxed{9 \\text{ people}}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Here’s a detailed proposal for an **Agentic AI solution** targeting **Proactive Disruption Management and Recovery** in Supply Chain Management and Logistics:\n",
       "\n",
       "---\n",
       "\n",
       "## Agentic AI Solution: **Supply Chain Resilience Agent (SCRA)**\n",
       "\n",
       "### Overview:\n",
       "The **Supply Chain Resilience Agent (SCRA)** is a distributed intelligent agent system designed to autonomously monitor, predict, and mitigate disruptions in complex supply chains. It acts proactively and collaboratively by continuously analyzing multi-source data, anticipating risks, and orchestrating mitigation strategies to maintain seamless operations.\n",
       "\n",
       "---\n",
       "\n",
       "### Key Components:\n",
       "\n",
       "1. **Multi-Source Data Integration & Monitoring Agent**  \n",
       "   - Continuously ingests and fuses real-time data from:  \n",
       "     - Supplier performance dashboards (lead times, quality metrics)  \n",
       "     - Logistics tracking (GPS, IoT sensors, transportation status)  \n",
       "     - External signals (weather forecasts, geopolitical events, market trends)  \n",
       "     - Internal ERP and inventory management systems  \n",
       "   - Utilizes anomaly detection to flag early disruption indicators.\n",
       "\n",
       "2. **Predictive Disruption Analytics Agent**  \n",
       "   - Employs machine learning models trained on historical disruption, delay, and demand data to predict the likelihood, location, and impact of potential disruptions.  \n",
       "   - Estimates ripple effects across suppliers, logistics, inventory, and delivery schedules.\n",
       "\n",
       "3. **Autonomous Decision-Making & Execution Agent**  \n",
       "   - Based on predicted disruptions and real-time status, proactively generates multi-step recovery plans including:  \n",
       "     - Alternative routing and carrier assignments  \n",
       "     - Dynamic inventory policy updates (e.g., safety stock adjustments)  \n",
       "     - Supplier substitution and contract renegotiations  \n",
       "   - Executes approved plans autonomously, interfacing directly with ERP, transportation management systems (TMS), and supplier portals.\n",
       "\n",
       "4. **Multi-Agent Coordination and Negotiation Framework**  \n",
       "   - Represents different stakeholders (manufacturers, suppliers, 3PLs, distributors) as independent but cooperative agents.  \n",
       "   - Negotiates and coordinates mitigation strategies to balance individual and collective objectives (cost, timeliness, risk).  \n",
       "   - Uses game-theoretic or reinforcement learning approaches to optimize across the network, ensuring no stakeholder is disproportionately impacted.\n",
       "\n",
       "5. **Continuous Learning and Feedback Loop**  \n",
       "   - Learns from actions taken and their outcomes to improve predictive accuracy and decision policies over time.  \n",
       "   - Integrates human feedback as needed for complex or unprecedented disruptions.\n",
       "\n",
       "6. **Compliance and Sustainability Agent**  \n",
       "   - Ensures autonomous actions comply with regulatory constraints (e.g., customs, safety).  \n",
       "   - Optimizes decisions for environmental sustainability metrics, such as carbon footprint and waste reduction.\n",
       "\n",
       "---\n",
       "\n",
       "### Workflow Example:\n",
       "\n",
       "1. **Monitoring & Early Detection:**  \n",
       "   SCRA ingests weather alerts indicating a hurricane that could disrupt a major shipping port in three days.\n",
       "\n",
       "2. **Prediction:**  \n",
       "   The Predictive Analytics Agent calculates a high risk to shipments scheduled arriving at that port and estimates cascading delays downstream.\n",
       "\n",
       "3. **Proactive Planning:**  \n",
       "   The Decision-Making Agent generates alternative routing plans, identifies nearby ports, assesses inventory buffers, and searches for secondary suppliers.\n",
       "\n",
       "4. **Coordination:**  \n",
       "   SCRA agents representing suppliers, logistics providers, and distributors negotiate the best shared recovery plan balancing rerouting costs vs. delivery urgency.\n",
       "\n",
       "5. **Execution:**  \n",
       "   Approved rerouting orders are automatically sent to carriers; inventory orders are adjusted to increase safety stock at regional warehouses.\n",
       "\n",
       "6. **Adaptation:**  \n",
       "   The system monitors real-time execution and updates plans dynamically as conditions evolve.\n",
       "\n",
       "---\n",
       "\n",
       "### Benefits:\n",
       "\n",
       "- **Significantly reduces reaction times** to disruptions and minimizes cascading failures.\n",
       "- Improves **overall supply chain resilience** and customer satisfaction.\n",
       "- Lowers operational **costs by optimizing contingencies** and avoiding rush or penalty fees.\n",
       "- Enhances **collaboration and transparency** among diverse stakeholders.\n",
       "- Supports **sustainability goals** and regulatory compliance dynamically.\n",
       "\n",
       "---\n",
       "\n",
       "### Technologies Involved:\n",
       "\n",
       "- IoT and edge sensor integration  \n",
       "- Advanced ML models: time series forecasting, anomaly detection, reinforcement learning  \n",
       "- Multi-agent systems and negotiation algorithms  \n",
       "- APIs for ERP, TMS, supplier systems integration  \n",
       "- Natural language processing for geopolitical intelligence feeds  \n",
       "- Cloud infrastructure for scalable processing and data storage  \n",
       "\n",
       "---\n",
       "\n",
       "### Conclusion:\n",
       "\n",
       "The **Supply Chain Resilience Agent (SCRA)** leverages the unique strengths of agentic AI to transform supply chain disruption management from reactive firefighting into a proactive, autonomous, and adaptive process. This results in a stronger, more agile, and cost-effective supply chain network capable of navigating today's volatile environment.\n",
       "\n",
       "---\n",
       "\n",
       "If you want, I can also draft a high-level implementation roadmap or identify specific vendors and tech stacks suitable for building this solution. Would that be helpful?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\",\n",
    "    \"content\": \"Pick a business area that you think is worth exploring for an Agentic AI opportunity.\"}\n",
    "    ]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.choices[0].message.content\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Given this business area: {business_idea}, identify a pain point that could be solved with an Agentic AI.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Everytime there is a new \"messages\", then we must have a new \"response\" as well, with \"model\" and \"messages\" being\n",
    "# the two required parameters for the OpenAI API call\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "pain_point = response.choices[0].message.content\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"Given this problem: {pain_point}, in this field: {business_idea}, propose a Agentic AI solution.\"\n",
    "}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "solution = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(solution))\n",
    "\n",
    "# Hallmark of Agentic AI solution: autonamy to choose things to say\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
